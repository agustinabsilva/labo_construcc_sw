# -*- coding: utf-8 -*-
"""entrega3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LFbZQZJcaCfvs_nH-SkSZmpcdtx5umuJ
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm

empleados = pd.read_csv("data.csv")

#Manual encoded para habilidad
habilidad_map = {
    "Assembler": 1, "Java": 2, "Python": 3, "SQL": 4}
empleados['Habilidad_Encoded'] = empleados['Habilidad'].map(habilidad_map)
empleados["Nivel_Encoded"] = empleados["Nivel"]
empleados

#Escalo las columnas que necesito
escalador = MinMaxScaler()
empleados[['Habilidad_Encoded', 'Nivel_Encoded']] = escalador.fit_transform(empleados[['Habilidad_Encoded', 'Nivel_Encoded']])
empleados.head()

#Entreno las columnas que necesito
n_clusters = 12
X = empleados[['Habilidad_Encoded', 'Nivel_Encoded']]
kmeans = KMeans(n_clusters, random_state=12)
empleados['Cluster'] = kmeans.fit_predict(X)
empleados.head()

plt.figure(figsize=(8, 6), dpi=100)

# Generar colores dinámicamente según el número de clusters
num_clusters = kmeans.n_clusters
colormap = cm.get_cmap("tab10", num_clusters)  # Compatible con versiones anteriores
colores = [colormap(i / num_clusters) for i in range(num_clusters)]

# Mapeo de clusters con nombres
etiquetas_clusters = { 0: "Python Intermedio",
    1: "Java Avanzado",
    2: "SQL Avanzado",
    3: "Habilidades blandas con M. Vargas",
    4: "Ayudante de 1RA en Labo",
    5: "Assembler Intermedio",
    6: "Python Avanzado",
    7: "Java Intermedio",
    8: "SQL Intermedio",
    9: "BBDD y Peronismo by Lucyfer",
    10: "SpringBoot con M. Sempken",
    11: "Assembler Avanzado"

}

# Ajustar etiquetas según la cantidad de clusters generados
etiquetas_validas = {i: etiquetas_clusters.get(i, f"Cluster {i}") for i in range(num_clusters)}

# Graficar los puntos con menor jitter
for cluster in range(num_clusters):
    subset = empleados[empleados["Cluster"] == cluster]

    # Reducimos la desviación estándar del jitter a 0.03 para menor distorsión
    x_jitter = subset["Habilidad_Encoded"] + np.random.normal(0, 0.03, size=len(subset))
    y_jitter = subset["Nivel_Encoded"] + np.random.normal(0, 0.03, size=len(subset))

    plt.scatter(x_jitter, y_jitter, marker="o", s=60,
                color=colores[cluster], alpha=0.7, label=etiquetas_validas[cluster])

    # Graficar centroides
    plt.scatter(kmeans.cluster_centers_[:, 0][cluster],
                kmeans.cluster_centers_[:, 1][cluster],
                marker="P", s=150, color=colores[cluster], edgecolors="black", linewidth=1.5)

plt.title("k-Means Recomendaciones de cursos", fontsize=18)
plt.xlabel("Habilidad Encoded", fontsize=14)
plt.ylabel("Nivel", fontsize=14)

# Mover la leyenda fuera del gráfico
plt.legend(title="Curso Recomendado", bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=12)

plt.tight_layout()  # Ajustar el diseño para que no se corte nada
plt.show()